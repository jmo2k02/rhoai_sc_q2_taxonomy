---
version: 3
domain: Plattform Architektur
created_by: jm02k02
document_outline: |
  Sach- und Planungs-Informationen über die Architektur der Internen
  Container Plattform (ICP).
seed_examples:
  #############
  # Context 1 #
  #############
  - context: |
      **Zone München (MUC)** fungiert als unser Hauptstandort und
      beherbergt den Großteil unserer kritischen
        Produktionsworkloads. Diese Zone umfasst sowohl traditionelle
        Unternehmensanwendungen als auch moderne
        Cloud-native Microservices-Architekturen. Der Schwerpunkt liegt
        auf hochverfügbaren Services mit stringenten
        SLA-Anforderungen. Aufgrund der zentralen Rolle als
        Haupt-Datacenter verzeichnet München kontinuierlich das stärkste
        Wachstum bei allen Ressourcenkategorien. Besonders bemerkenswert
        ist die Zunahme bei GPU-Ressourcen,
        die durch den verstärkten Einsatz von Machine Learning und
        AI-Workloads getrieben wird.

      **Zone Frankfurt (FRA)** dient primär als Disaster Recovery Standort
      und Secondary Site für geschäftskritische
        Anwendungen. Diese Zone hat sich in den letzten Jahren von einer
        reinen Backup-Infrastruktur
        zu einem aktiven Produktionsstandort entwickelt, der sowohl
        DR-Szenarien als auch Load Balancing
        zwischen den Standorten unterstützt. Das Wachstum in Frankfurt
        spiegelt unsere Multi-Site-Strategie
        wider und zeigt eine konstante Steigerung der Kapazitätsanforderungen,
        insbesondere bei Storage für Datenreplikation
        und RAM für In-Memory-Caching-Lösungen.

      **Zone Hamburg (HAM)** fokussiert sich auf Development und Testing
      Workloads sowie auf weniger kritische Produktionsanwendungen.
        Diese Zone charakterisiert sich durch hohe Volatilität in der
        Ressourcennutzung, da Entwicklungs- und Testumgebungen häufig
        auf- und abgebaut werden. Das Wachstum ist geprägt von einem
        steigenden Bedarf an vCPU-Ressourcen für parallele Build-Prozesse
        und Container-Orchestrierung. Storage-Anforderungen wachsen
        durch die Notwendigkeit, verschiedene Versionsstände von Anwendungen
        und Testdaten vorzuhalten.
    questions_and_answers:
      - question: |
          Welche Hauptfunktion erfüllt Zone München (MUC) und wodurch
          wird das GPU-Ressourcen-Wachstum getrieben?
        answer: |
          Die Zone München (MUC) ist der Hauptstandort der Container
          Plattform und hat seinen Schwerpunkt auf hochverfügbaren Services
          mit stringenten SLA-Anforderungen.
          Aufgrund von verstärktem Einsatz von ML und AI-Workloads,
          ist auch ein bemerkenswerter Wachstum bei GPU-Ressourcen zu
          verzeichnen.
      - question: |
          Wie hat sich Zone Frankfurt (FRA) entwickelt und welche
          Ressourcen zeigen besonders starkes Wachstum?
        answer: |
          Die Zone Frankfurt (FRA) hat sich von einer reinen
          Backup-Infrastruktur
          zu einem aktiven Produktionsstandort entwickelt.
          Dabei zeigen vor allem Storage für Datenreplikation und RAM für
          In-Memory-Caching-Lösungen eine konstante Steigerung.
      - question: |
          Wodurch charakterisiert sich die Zone Hamburg (HAM) und warum
          steigen die vCPU-Anforderungen?
        answer: |
          Die Zone Hamburg (HAM) charakterisiert sich durch hohe Volatilität
          in der Ressourcennutzung.
          Der Bedarf an vCPU-Ressourcen steigt aufgrund vermehrter paralleler
          Build-Prozesse und Container-Orchestrierung.
  #############
  # Context 2 #
  #############
  - context: |
      ## Kapazitätsplanung und Strategische Ausrichtung

      **Mittelfristige Prognose (2026-2027):** Basierend auf den
      aktuellen Trends erwarten wir eine Fortsetzung des Wachstums bei
        moderaten Raten. Für 2026 prognostizieren wir einen
        Gesamtbedarf von etwa 15.000 vCPU-Kernen, 280 GPU-Kernen,
        60.000 GB RAM
        und 950 TB Storage. Die Wachstumsraten werden sich
        voraussichtlich bei etwa 18-20% stabilisieren, da die
        initiale Migrationswelle von Legacy-Systemen abebbt.

      **Investitionspriorisierung:** GPU-Kapazitäten erfordern die
      höchste Aufmerksamkeit aufgrund der starken Nachfrage, hohen
      Beschaffungskosten und Risiken von Lieferengpässen.
        Eine strategische Vorabinvestition in GPU-Ressourcen wird empfohlen,
        um Engpässe zu vermeiden. Storage-Wachstum erfordert kontinuierliche
        Investitionen in Hochleistungsspeicher und Backup-Infrastruktur.

      **Zonale Entwicklungsstrategie:** Berlin als Innovationsstandort
      wird überproportional wachsen und erfordert flexible Kapazitätsplanungen.
        München bleibt der Haupttreiber für absolute Kapazitätserweiterungen.
        Frankfurt entwickelt sich zu einem vollwertigen Produktionsstandort
        und benötigt entsprechende Infrastrukturinvestitionen.

      **Kostenoptimierung:** Durch die Implementierung von Cluster-Autoscaling
      und ressourcenbasierter Abrechnung können Effizienzgewinne von
        15-20% realisiert werden. Die Einführung von Spot-Instances für
        nicht-kritische Workloads kann weitere Kosteneinsparungen ermöglichen.
      ## Empfehlungen und Nächste Schritte

      Die Kapazitätsplanung sollte quartalsweise überprüft und angepasst
      werden, um auf sich ändernde Geschäftsanforderungen reagieren zu
        können. Die Implementierung von Monitoring-Tools für
        Ressourcennutzung und Predictive Analytics wird empfohlen,
        um die Planungsgenauigkeit
        zu verbessern.

      Eine strategische Partnerschaft mit Hardware-Anbietern für GPU-Kapazitäten
      sollte etabliert werden, um Lieferengpässe zu vermeiden.
        Die Evaluierung von Hybrid-Cloud-Szenarien für Spitzenlasten kann
        die Kapazitätsflexibilität erhöhen, ohne die Grundinvestition zu
        erhöhen.


    questions_and_answers:
      - question: |
          Welche Kapazitätsprognose wird für 2026 erwartet?
        answer: |
          Für 2026 wird ein Gesamtbedarf von etwa 15.000 vCPU-Kernen,
          280 GPU-Kernen, 60.000 GB RAM und 950 TB Storage prognostiziert.
      - question: |
          Warum erfordern GPU-Kapazitäten die höchste Investitionspriorität?
        answer: |
          GPU-Kapazitäten erfordern die höchste Aufmerksamkeit aufgrund
          der starken Nachfrage, hohen Beschaffungskosten und Risiken von
          Lieferengpässen.
      - question: |
          Welche Kostenoptimierungen sind möglich?
        answer: |
          Mögliche Kostenoptimierungen, wären die Implementierung von
          Cluster-Autoscaling und ressourcenbasierter Abrechnung,
          wodurch Effizienzgewinne von 15-20% realisiert werden könnten.
  #############
  # Context 3 #
  #############
  - context: |
      ### 1.1 Standard-Namensschema
      ```
      <appteam-id>-<umgebung>-<optional-suffix>
      ```

      ### 1.2 Umgebungs-Suffixe
      | Umgebung | Suffix | Beschreibung | Beispiel |
      |----------|--------|--------------|----------|
      | Entwicklung | `dev` | Entwicklungsumgebung | `ref416-oracle-dev` |
      | Qualitätssicherung | `qs` | Test- und QS-Umgebung | `ref416-oracle-qs` |
      | Integration | `int` | Integrationsumgebung | `ref416-oracle-int` |
      | Produktion | `prod` | Produktionsumgebung | `ref416-oracle-prod` |

      ### 1.3 Namespace-Beispiele
      ```bash
      # Gültige Namespace-Namen
      ref416-shop-dev
      ref416-shop-qs
      ref416-shop-prod
      fin-api-dev
      fin-api-prod
      crm-backend-int
      ```

      ### 1.4 Namespace-Beschränkungen
      - Maximale Länge: 63 Zeichen
      - Nur Kleinbuchstaben, Zahlen und Bindestriche
      - Muss mit Buchstabe oder Zahl beginnen und enden
      - **VERBOTEN**: `default`, `kube-*`, `openshift-*`, `icp-*`

      ## 2. Container Image-Konventionen

      ### 2.1 Quay Registry Schema
      ```
      cpk.quay.asg.net/<app-team-name>-<umgebung>/<repo>:<tag>
      ```

      ### 2.2 Image-Tag-Konventionen

      #### Entwicklungsumgebung
      ```bash
      # Erlaubt - automatische Updates
      cpk.quay.asg.net/ref416-oracle-dev/backend:latest
      cpk.quay.asg.net/ref416-oracle-dev/frontend:main
      cpk.quay.asg.net/ref416-oracle-dev/api:develop
      ```


    questions_and_answers:
      - question: |
          Wie lautet das Standard-Namensschema für Kubernetes Namespaces?
        answer: |
          Das Standard-Namensschema lautet:
          ```
          <appteam-id>-<umgebung>-<optional-suffix>
          ```
          An einem konkreten Beispiel könnte dies so aussehen
          | Umgebung | Suffix | Beschreibung | Beispiel |
          |----------|--------|--------------|----------|
          | Entwicklung | `dev` | Entwicklungsumgebung | `ref416-oracle-dev` |
      - question: |
          Welche verschiedenen Umgebungen gibt es und welches
          Suffix haben sie jeweils?
        answer: |
          Es gibt 4 verschiedene Umgebungen.
            - Entwicklungsumgebung, Suffix = `dev`
            - Test- und QS-Umgebung, Suffix = `qs`
            - Integrationsumgebung, Suffix = `int`
            - Produkitonsumgebung, Suffix = `prod`
      - question: |
          Wie ist das Quay Registry Schema aufgebaut?
        answer: |
          Das Quay Registry Schema ist folgendermaßen aufgebaut:
          ```
          cpk.quay.asg.net/<app-team-name>-<umgebung>/<repo>:<tag>
          ```
          Komponenten des Schemas:
            - cpk.quay.asg.net - Die Basis-URL der unternehmensinternen
            Quay Registry
            - <app-team-name>-<umgebung> - Die Organisation, bestehend
            aus der Team-ID und der Umgebung (z.B. ref416-oracle-dev)
            - <repo> - Der Repository-Name (z.B. backend, frontend, api)
            - <tag> - Der Image-Tag (z.B. latest, main, develop oder
            Versionsnummern)

  #############
  # Context 4 #
  #############
  - context: |
      ## Zuständigkeitsmatrix der Toollandschaft

      tools:
        - tool: Red Hat OpenShift
          aufgabe: Container-Orchestrierung
          beschreibung: >
            Kubernetes-basierte Container-Plattform als Basis für ICP
          abteilung: ICP-Team
          technisch: ICP-Team
          betrieblich: ICP-Team
          plattform_empfehlung: Empfohlen
          risiko: Niedrig
          kommentar: Kern der ICP-Plattform

        - tool: Red Hat Quay (CPK)
          aufgabe: Container Registry
          beschreibung: >
            Zentrale Registry für Container-Images unter cpk.quay.asg.net
          abteilung: ICP-Team
          technisch: ICP-Team
          betrieblich: ICP-Team
          plattform_empfehlung: Verpflichtend
          risiko: Niedrig
          kommentar: Team-spezifische Organisationen

        - tool: Argo CD
          aufgabe: GitOps Deployment
          beschreibung: >
            Kontinuierliche Bereitstellung über GitOps-Prinzipien
          abteilung: ICP-Team
          technisch: ICP-Team
          betrieblich: DevOps-Team
          plattform_empfehlung: Empfohlen
          risiko: Niedrig
          kommentar: Integration in ICP-Workflows

        - tool: Argo Workflows
          aufgabe: Workflow-Orchestrierung
          beschreibung: >
            Komplexe CI/CD-Pipelines und Batch-Processing
          abteilung: ICP-Team
          technisch: ICP-Team
          betrieblich: DevOps-Team
          plattform_empfehlung: Empfohlen
          risiko: Mittel
          kommentar: Für komplexe Workflows

        - tool: Tekton Pipelines
          aufgabe: CI/CD Pipelines
          beschreibung: >
            Native Kubernetes CI/CD mit ClusterTask "save-pipeline-logs"
          abteilung: ICP-Team
          technisch: ICP-Team
          betrieblich: ICP-Team
          plattform_empfehlung: Empfohlen
          risiko: Niedrig
          kommentar: Standard für Image-Builds

        - tool: Jenkins
          aufgabe: Legacy CI/CD
          beschreibung: >
            Bestehende Jenkins-Instanzen für Migration
          abteilung: DevOps-Team
          technisch: External-ISV
          betrieblich: DevOps-Team
          plattform_empfehlung: Migration geplant
          risiko: Hoch
          kommentar: Ablösung durch Tekton

        - tool: Helm 3
          aufgabe: Package Management
          beschreibung: >
            Kubernetes-Anwendungspaketierung (MUSS-Kriterium)
          abteilung: Applikationsteams
          technisch: Applikationsteams
          betrieblich: ICP-Team
          plattform_empfehlung: Verpflichtend
          risiko: Niedrig
          kommentar: Helm 2 nicht mehr unterstützt

    questions_and_answers:
      - question: |
          Welche Rolle spielt Red Hat OpenShift in der ICP-Toollandschaft und
          wer ist dafür zuständig?
        answer: |
          RedHat OpenShift ist eine Kubernetes-basierte Container-Plattform und
          dient als Basis für die ICP.
          Das ICP Team hat die volle Verantowrtung für RedHat OpenShift.
      - question: |
          Welches Legacy-System wird durch Tekton abgelöst?
        answer: |
          Das Jenkins System soll durch Tekton Pipelines ersetzt werden. Der
          Prozess ist aktuell noch in der Migration.
      - question: |
          Warum ist Helm 3 verpflichtend und welche Plattform-Empfehlung hat
          Red Hat Quay (CPK)?
        answer: |
          Helm3 ist verpflichtend, weil die Unterstützung von Helm2 beendet
          wurde. RedHat Quay hat eine verpflichtende Empfehlung als Standard
          Container Registry.
  #############
  # Context 5 #
  #############
  - context: |
      ## 2. Image Promotion Pipeline

      ### 2.1 Umgebungslandschaft

      ```
      Entwicklung → Staging → Pre-Production → Production
          ↓            ↓           ↓              ↓
        dev-ns      staging-ns   preprod-ns    prod-ns
      ```

      ### 2.2 Promotion-Prozess

      #### Phase 1: Development
      **Verantwortlichkeit:** Entwicklungsteams

      **Prozess:**
      1. Entwickler erstellt Dockerfile basierend auf approved
      Base/Runtime Images
      2. Lokaler Build und Tests
      3. Push zu Development Registry
      4. Automatische Bereitstellung in Development Namespace

      **Registry:** `cpk.quay.asg.net/<app-team-name>-dev/<repo>:<tag>`

      **Gating Criteria:**
      - Successful Build
      - Unit Tests bestanden
      - Code Quality Gates erfüllt

      #### Phase 2: Staging
      **Verantwortlichkeit:** QA Teams

      **Prozess:**
      1. Automatischer Trigger nach erfolgreichem Development Build
      2. Image wird zu Staging Registry promoted
      3. Deployment in Staging Umgebung
      4. Automatisierte Integration Tests

      **Registry:** `cpk.quay.asg.net/<app-team-name>-staging/<repo>:<tag>`

      **Gating Criteria:**
      - Security Scan bestanden (Critical/High Vulnerabilities = 0)
      - Integration Tests erfolgreich
      - Performance Tests bestanden

      #### Phase 3: Pre-Production
      **Verantwortlichkeit:** Release Management

      **Prozess:**
      1. Manuelle Promotion nach Staging Approval
      2. Image wird zu Pre-Production Registry promoted
      3. Smoke Tests in produktionsähnlicher Umgebung
      4. Change Management Approval

      **Registry:** `cpk.quay.asg.net/<app-team-name>-preprod/<repo>:<tag>`

      **Gating Criteria:**
      - Change Approval erteilt
      - Smoke Tests bestanden
      - Rollback Plan dokumentiert


    questions_and_answers:
      - question: |
          Wie sieht die vierstufige Image Promotion Pipeline aus und
          welche Namespaces werden durchlaufen?
        answer: |
          Die Stufen Entwicklung, Staging, Pre-Production, Production
          werden von Links nach Rechts durchlaufen.
          Die dazugehörigen namespaces sind der dev-ns, staging-ns,
          preprod-ns und prod-ns.
      - question: |
          Welche Gating-Kriterien müssen in der Development-Phase erfüllt
          werden und wer ist dafür verantwortlich?
        answer: |
          Um all Gating-Kriterien zu erfüllen, muss der Build Prozess
          erfolgreich abgeschlossen werden, alle Unit-Tests bestanden werden
            und alle Code Quality Gates erfüllt sein.
          Dafür ist immer das jeweilige Entwicklungsteam verantwortlich.
      - question: |
          Was sind die Kernunterschiede zwischen Staging und Pre-Production
          Phase bezüglich Verantwortlichkeit und Gating-Kriterien?
        answer: |
          Die Kernunterschiede sind:
            - Staging konzentriert sich auf technische Qualitätssicherung
            (Sicherheit, Tests, Performance)
            - Pre-Production ist fokussiert auf organisatorische
            Freigabe-Prozesse (Genehmigungen, Dokumentation, Rollback-Planung)
            - Der Übergang von automatisiert (Staging) zu manuell kontrolliert
            (Pre-Production) spiegelt die zunehmende
            Kritikalität im Promotion Prozess wider
document:
  repo: "https://github.com/SherylGitCamp/rhoai_sc_q2_taxonomy.git"
  commit: 7afe7c77faea7f1c007e84477aba4d357d2e0752
  patterns:
    - "documents/plattform_architektur/*.md"
